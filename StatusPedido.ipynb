{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status dos pedidos abertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo C:\\Users\\corteda1\\Mars Inc\\Brazil_MW_PlanningComex - Documents\\__INPUT_DATA_FOR_AUTOMATION__\\MRP\\Python\\contagem_status.xlsx atualizado com sucesso para o arquivo Piloto - MRP_01.08 - MPS e Ciclo P07.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Pasta onde os novos arquivos serão verificados\n",
    "pasta_dados = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/4 - MRP/1 - MPS Daily/'\n",
    "\n",
    "# Arquivo de registro para controlar a data da última execução para cada arquivo\n",
    "arquivo_log = 'last_run_log.txt'\n",
    "\n",
    "def verificar_novo_arquivo():\n",
    "    arquivos = os.listdir(pasta_dados)\n",
    "    arquivos = [arquivo for arquivo in arquivos if arquivo.startswith('Piloto - MRP_') and arquivo.endswith('.xlsx')]\n",
    "    if arquivos:\n",
    "        arquivo_recente = max(arquivos, key=lambda x: os.path.getmtime(os.path.join(pasta_dados, x)))\n",
    "        return arquivo_recente\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def carregar_log():\n",
    "    if os.path.exists(arquivo_log):\n",
    "        with open(arquivo_log, 'r') as f:\n",
    "            log = f.read().strip().split('\\n')\n",
    "        log_dict = {linha.split(',')[0]: linha.split(',')[1] for linha in log}\n",
    "        return log_dict\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def salvar_log(log_dict):\n",
    "    with open(arquivo_log, 'w') as f:\n",
    "        for arquivo, data in log_dict.items():\n",
    "            f.write(f\"{arquivo},{data}\\n\")\n",
    "\n",
    "def verificar_ultima_execucao(arquivo, log_dict):\n",
    "    return log_dict.get(arquivo, None)\n",
    "\n",
    "def registrar_ultima_execucao(arquivo, data, log_dict):\n",
    "    log_dict[arquivo] = data\n",
    "\n",
    "def processar_arquivo(arquivo, log_dict):\n",
    "    # Caminho completo do arquivo\n",
    "    caminho_arquivo = os.path.join(pasta_dados, arquivo)\n",
    "    # Ler a aba específica do arquivo Excel\n",
    "    aba = '8. Entrega Real'\n",
    "    try:\n",
    "        df = pd.read_excel(caminho_arquivo, sheet_name=aba)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Verificar se a coluna 'Status' está presente\n",
    "    if 'Status' not in df.columns:\n",
    "        print(f\"O arquivo {arquivo} não contém a coluna 'Status'. Ignorando.\")\n",
    "        return\n",
    "\n",
    "    # Supondo que o nome da coluna é 'Status', mas pode haver espaços extras\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Definir todas as categorias de status desejadas\n",
    "    categorias_status = [\"Ag. Confirmação\", \"Confirmado\", \"Parcialmente conf\", \"Recusado\", \"Contrato Pendente\"]\n",
    "\n",
    "    # Excluir os valores em branco na coluna 'Status'\n",
    "    df = df[df['Status'].notna()]\n",
    "\n",
    "    # Contar a ocorrência de cada status\n",
    "    contagem_status = df['Status'].value_counts().reindex(categorias_status, fill_value=0)\n",
    "\n",
    "    # Obter a data atual\n",
    "    data_atual = datetime.today().date().strftime('%d/%m/%Y')\n",
    "\n",
    "    # Verificar se o processamento já foi feito hoje para este arquivo\n",
    "    ultima_execucao = verificar_ultima_execucao(arquivo, log_dict)\n",
    "    if ultima_execucao == data_atual:\n",
    "        print(f\"O processamento para o arquivo {arquivo} já foi realizado hoje.\")\n",
    "        return\n",
    "\n",
    "    # Criar um DataFrame final no formato \"long\" com a data, status e contagem apenas para \"Confirmado\"\n",
    "    df_final = pd.DataFrame({\n",
    "        'data': [data_atual],\n",
    "        'status': ['Confirmado'],\n",
    "        'contagem': [contagem_status['Confirmado']],\n",
    "        'fornecedor': [None]\n",
    "    })\n",
    "\n",
    "    # Para as categorias de status exceto \"Confirmado\", adicionar a lista de fornecedores únicos e suas contagens\n",
    "    fornecedores_unicos = df[df['Status'] != 'Confirmado'][['Status', 'Fornecedor']]\n",
    "    contagem_fornecedores = fornecedores_unicos.groupby(['Status', 'Fornecedor']).size().reset_index(name='contagem')\n",
    "\n",
    "    # Criar um DataFrame com linhas separadas para cada fornecedor com suas respectivas contagens\n",
    "    fornecedores_separados = []\n",
    "    for _, row in contagem_fornecedores.iterrows():\n",
    "        fornecedores_separados.append([data_atual, row['Status'], row['contagem'], row['Fornecedor']])\n",
    "\n",
    "    df_fornecedores = pd.DataFrame(fornecedores_separados, columns=['data', 'status', 'contagem', 'fornecedor'])\n",
    "\n",
    "    # Concatenar os DataFrames df_final e df_fornecedores\n",
    "    df_final_completo = pd.concat([df_final, df_fornecedores], ignore_index=True)\n",
    "\n",
    "    # Nome do novo arquivo Excel\n",
    "    diretorio_destino = Path('C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python')\n",
    "    arquivo_destino = diretorio_destino / 'contagem_status.xlsx'\n",
    "\n",
    "    # Verificar se o diretório de destino existe, criar se não existir\n",
    "    diretorio_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Carregar o arquivo Excel ou criar um novo DataFrame vazio\n",
    "    if arquivo_destino.exists():\n",
    "        # Carregar o arquivo existente\n",
    "        try:\n",
    "            wb = load_workbook(arquivo_destino)\n",
    "            if 'Status' in wb.sheetnames:\n",
    "                # Carregar o DataFrame da aba 'Status'\n",
    "                df_anterior = pd.read_excel(arquivo_destino, sheet_name='Status')\n",
    "                # Mesclar os novos dados com os dados existentes\n",
    "                df_atualizado = pd.concat([df_anterior, df_final_completo], ignore_index=True)\n",
    "                # Escrever de volta para a aba 'Status'\n",
    "                with pd.ExcelWriter(arquivo_destino, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "                    df_atualizado.to_excel(writer, sheet_name='Status', index=False)\n",
    "            else:\n",
    "                # Caso a aba 'Status' não exista, criar uma nova\n",
    "                with pd.ExcelWriter(arquivo_destino, engine='openpyxl', mode='a') as writer:\n",
    "                    df_final_completo.to_excel(writer, sheet_name='Status', index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo {arquivo_destino}: {e}\")\n",
    "    else:\n",
    "        # Criar um novo arquivo Excel com os dados\n",
    "        with pd.ExcelWriter(arquivo_destino, engine='openpyxl', mode='w') as writer:\n",
    "            df_final_completo.to_excel(writer, sheet_name='Status', index=False)\n",
    "\n",
    "    print(f\"Arquivo {arquivo_destino} atualizado com sucesso para o arquivo {arquivo}.\")\n",
    "    registrar_ultima_execucao(arquivo, data_atual, log_dict)\n",
    "\n",
    "def main():\n",
    "    log_dict = carregar_log()\n",
    "    novo_arquivo = verificar_novo_arquivo()\n",
    "    if not novo_arquivo:\n",
    "        print(\"Não há novos arquivos para processar. Encerrando o programa.\")\n",
    "        return\n",
    "\n",
    "    processar_arquivo(novo_arquivo, log_dict)\n",
    "    salvar_log(log_dict)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overdue PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx atualizado com sucesso para o arquivo Piloto - MRP_01.08 - MPS e Ciclo P07.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Pasta onde os novos arquivos serão verificados\n",
    "pasta_dados = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/4 - MRP/1 - MPS Daily/'\n",
    "\n",
    "# Arquivo de registro para controlar a data da última execução para cada arquivo\n",
    "arquivo_log = 'last_run_log.txt'\n",
    "\n",
    "def verificar_novo_arquivo():\n",
    "    arquivos = os.listdir(pasta_dados)\n",
    "    arquivos = [arquivo for arquivo in arquivos if arquivo.startswith('Piloto - MRP_') and arquivo.endswith('.xlsx')]\n",
    "    if arquivos:\n",
    "        arquivo_recente = max(arquivos, key=lambda x: os.path.getmtime(os.path.join(pasta_dados, x)))\n",
    "        return arquivo_recente\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def carregar_log():\n",
    "    if os.path.exists(arquivo_log):\n",
    "        with open(arquivo_log, 'r') as f:\n",
    "            log = f.read().strip().split('\\n')\n",
    "        log_dict = {linha.split(',')[0]: linha.split(',')[1] for linha in log}\n",
    "        return log_dict\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def salvar_log(log_dict):\n",
    "    with open(arquivo_log, 'w') as f:\n",
    "        for arquivo, data in log_dict.items():\n",
    "            f.write(f\"{arquivo},{data}\\n\")\n",
    "\n",
    "def verificar_ultima_execucao(arquivo, log_dict):\n",
    "    return log_dict.get(arquivo, None)\n",
    "\n",
    "def registrar_ultima_execucao(arquivo, data, log_dict):\n",
    "    log_dict[arquivo] = data\n",
    "\n",
    "def processar_arquivo(arquivo, log_dict):\n",
    "    # Caminho completo do arquivo\n",
    "    caminho_arquivo = os.path.join(pasta_dados, arquivo)\n",
    "    # Ler a aba específica do arquivo Excel\n",
    "    aba = '7. Pedidos'\n",
    "    try:\n",
    "        df = pd.read_excel(caminho_arquivo, sheet_name=aba)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Verificar se a coluna 'Overdue PO' está presente\n",
    "    if 'Overdue PO' not in df.columns:\n",
    "        print(f\"O arquivo {arquivo} não contém a coluna 'Overdue PO'. Ignorando.\")\n",
    "        return\n",
    "\n",
    "    # Supondo que o nome da coluna é 'overdue po', mas pode haver espaços extras\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Definir todas as categorias de status desejadas\n",
    "    categorias_status = [\"em dia\", \"atrasado\"]\n",
    "\n",
    "    # Contar a ocorrência de cada status e filtrar informações adicionais para \"atrasado\"\n",
    "    contagem_status = df['Overdue PO'].value_counts().reindex(categorias_status, fill_value=0)\n",
    "    dados_atrasado = df[df['Overdue PO'] == 'atrasado'][['Texto breve de material', 'Pedido', 'Material', 'DATA REAL']]\n",
    "\n",
    "    # Obter a data atual\n",
    "    data_atual = datetime.today().date().strftime('%d/%m/%Y')\n",
    "\n",
    "    # Criar um DataFrame final no formato \"long\" com a data, status e contagem\n",
    "    df_final = pd.DataFrame({\n",
    "        'data': [data_atual] * len(contagem_status),\n",
    "        'status': contagem_status.index,\n",
    "        'contagem': contagem_status.values\n",
    "    })\n",
    "\n",
    "    # Adicionar informações adicionais dos pedidos atrasados\n",
    "    if not dados_atrasado.empty:\n",
    "        df_atrasado = pd.DataFrame({\n",
    "            'data': [data_atual] * len(dados_atrasado),\n",
    "            'DATA REAL': dados_atrasado['DATA REAL'].values,\n",
    "            'status': ['atrasado'] * len(dados_atrasado),\n",
    "            'Cod. Material': dados_atrasado['Material'].values,\n",
    "            'Material': dados_atrasado['Texto breve de material'].values,\n",
    "            'Número do Pedido': dados_atrasado['Pedido'].values,\n",
    "            'contagem': [1] * len(dados_atrasado)\n",
    "        })\n",
    "        df_final = pd.concat([df_final, df_atrasado], ignore_index=True)\n",
    "\n",
    "    # Nome do novo arquivo Excel\n",
    "    arquivo_destino = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx'\n",
    "\n",
    "    # Carregar o arquivo existente ou criar um novo DataFrame se o arquivo não existir\n",
    "    if os.path.exists(arquivo_destino):\n",
    "        # Carregar a planilha existente sem sobrescrever outras abas\n",
    "        with pd.ExcelFile(arquivo_destino) as reader:\n",
    "            # Carregar todas as abas existentes em um dicionário\n",
    "            planilhas = {sheet: pd.read_excel(reader, sheet_name=sheet) for sheet in reader.sheet_names}\n",
    "        # Atualizar ou criar a aba 'overdue PO'\n",
    "        if 'overdue PO' in planilhas:\n",
    "            df_existente = planilhas['overdue PO']\n",
    "            df_final = pd.concat([df_existente, df_final], ignore_index=True)\n",
    "        planilhas['overdue PO'] = df_final\n",
    "    else:\n",
    "        planilhas = {'overdue PO': df_final}\n",
    "\n",
    "    # Salvar todas as abas de volta na planilha\n",
    "    with pd.ExcelWriter(arquivo_destino, engine='openpyxl') as writer:\n",
    "        for sheet_name, df_sheet in planilhas.items():\n",
    "            df_sheet.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"Arquivo {arquivo_destino} atualizado com sucesso para o arquivo {arquivo}.\")\n",
    "    registrar_ultima_execucao(arquivo, data_atual, log_dict)\n",
    "\n",
    "def main():\n",
    "    log_dict = carregar_log()\n",
    "    novo_arquivo = verificar_novo_arquivo()\n",
    "    if not novo_arquivo:\n",
    "        print(\"Não há novos arquivos para processar. Encerrando o programa.\")\n",
    "        return\n",
    "\n",
    "    processar_arquivo(novo_arquivo, log_dict)\n",
    "\n",
    "    salvar_log(log_dict)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx atualizado com sucesso para o arquivo Piloto - MRP_01.08 - MPS e Ciclo P07.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Pasta onde os novos arquivos serão verificados\n",
    "pasta_dados = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/4 - MRP/1 - MPS Daily/'\n",
    "\n",
    "# Arquivo de registro para controlar a data da última execução para cada arquivo\n",
    "arquivo_log = 'last_run_log.txt'\n",
    "\n",
    "def verificar_novo_arquivo():\n",
    "    arquivos = os.listdir(pasta_dados)\n",
    "    arquivos = [arquivo for arquivo in arquivos if arquivo.startswith('Piloto - MRP_') and arquivo.endswith('.xlsx')]\n",
    "    if arquivos:\n",
    "        arquivo_recente = max(arquivos, key=lambda x: os.path.getmtime(os.path.join(pasta_dados, x)))\n",
    "        return arquivo_recente\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def carregar_log():\n",
    "    if os.path.exists(arquivo_log):\n",
    "        with open(arquivo_log, 'r') as f:\n",
    "            log = f.read().strip().split('\\n')\n",
    "        log_dict = {linha.split(',')[0]: linha.split(',')[1] for linha in log}\n",
    "        return log_dict\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def salvar_log(log_dict):\n",
    "    with open(arquivo_log, 'w') as f:\n",
    "        for arquivo, data in log_dict.items():\n",
    "            f.write(f\"{arquivo},{data}\\n\")\n",
    "\n",
    "def verificar_ultima_execucao(arquivo, log_dict):\n",
    "    return log_dict.get(arquivo, None)\n",
    "\n",
    "def registrar_ultima_execucao(arquivo, data, log_dict):\n",
    "    log_dict[arquivo] = data\n",
    "\n",
    "def processar_arquivo(arquivo, log_dict):\n",
    "    # Caminho completo do arquivo\n",
    "    caminho_arquivo = os.path.join(pasta_dados, arquivo)\n",
    "    # Ler a aba específica do arquivo Excel\n",
    "    aba = '7. Pedidos'\n",
    "    try:\n",
    "        df = pd.read_excel(caminho_arquivo, sheet_name=aba)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Verificar se a coluna 'Case fill' está presente\n",
    "    if 'Case fill' not in df.columns:\n",
    "        print(f\"O arquivo {arquivo} não contém a coluna 'Case fill'. Ignorando.\")\n",
    "        return\n",
    "\n",
    "    # Supondo que o nome da coluna é 'Case fill', mas pode haver espaços extras\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Definir todas as categorias de status desejadas\n",
    "    categorias_status = [\"Not Full\", \"In full\"]\n",
    "\n",
    "    # Contar a ocorrência de cada status e filtrar informações adicionais para \"atrasado\"\n",
    "    contagem_status = df['Case fill'].value_counts().reindex(categorias_status, fill_value=0)\n",
    "    dados_atrasado = df[df['Case fill'] == 'Not Full'][['Texto breve de material', 'Pedido']]\n",
    "\n",
    "    # Obter a data atual\n",
    "    data_atual = datetime.today().date().strftime('%d/%m/%Y')\n",
    "\n",
    "    # Verificar se o processamento já foi feito hoje para este arquivo\n",
    "    #ultima_execucao = verificar_ultima_execucao(arquivo, log_dict)\n",
    "    #if ultima_execucao == data_atual:\n",
    "    #    print(f\"O processamento para o arquivo {arquivo} já foi realizado hoje.\")\n",
    "    #    return\n",
    "\n",
    "    # Criar um DataFrame final no formato \"long\" com a data, status e contagem\n",
    "    df_final = pd.DataFrame({\n",
    "        'data': [data_atual] * len(contagem_status),\n",
    "        'status': contagem_status.index,\n",
    "        'contagem': contagem_status.values\n",
    "    })\n",
    "\n",
    "    # Adicionar informações adicionais dos pedidos atrasados\n",
    "    if not dados_atrasado.empty:\n",
    "        df_atrasado = pd.DataFrame({\n",
    "            'data': [data_atual] * len(dados_atrasado),\n",
    "            'status': ['Not Full'] * len(dados_atrasado),\n",
    "            'Material': dados_atrasado['Texto breve de material'].values,\n",
    "            'Número do Pedido': dados_atrasado['Pedido'].values\n",
    "        })\n",
    "        df_final = pd.concat([df_final, df_atrasado], ignore_index=True)\n",
    "\n",
    "    # Nome do novo arquivo Excel\n",
    "    arquivo_destino = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx'\n",
    "\n",
    "    # Carregar o arquivo existente ou criar um novo DataFrame se o arquivo não existir\n",
    "    if os.path.exists(arquivo_destino):\n",
    "        # Carregar a planilha existente sem sobrescrever outras abas\n",
    "        with pd.ExcelFile(arquivo_destino) as reader:\n",
    "            # Carregar todas as abas existentes em um dicionário\n",
    "            planilhas = {sheet: pd.read_excel(reader, sheet_name=sheet) for sheet in reader.sheet_names}\n",
    "        # Atualizar ou criar a aba 'Case fill'\n",
    "        if 'Case fill' in planilhas:\n",
    "            df_existente = planilhas['Case fill']\n",
    "            df_final = pd.concat([df_existente, df_final], ignore_index=True)\n",
    "        planilhas['Case fill'] = df_final\n",
    "    else:\n",
    "        planilhas = {'Case fill': df_final}\n",
    "\n",
    "    # Salvar todas as abas de volta na planilha\n",
    "    with pd.ExcelWriter(arquivo_destino, engine='openpyxl') as writer:\n",
    "        for sheet_name, df_sheet in planilhas.items():\n",
    "            df_sheet.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"Arquivo {arquivo_destino} atualizado com sucesso para o arquivo {arquivo}.\")\n",
    "    registrar_ultima_execucao(arquivo, data_atual, log_dict)\n",
    "\n",
    "def main():\n",
    "    log_dict = carregar_log()\n",
    "    novo_arquivo = verificar_novo_arquivo()\n",
    "    if not novo_arquivo:\n",
    "        print(\"Não há novos arquivos para processar. Encerrando o programa.\")\n",
    "        return\n",
    "\n",
    "    processar_arquivo(novo_arquivo, log_dict)\n",
    "\n",
    "    salvar_log(log_dict)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo C:\\Users\\corteda1\\Mars Inc\\Brazil_MW_PlanningComex - Documents\\__INPUT_DATA_FOR_AUTOMATION__\\MRP\\Python\\contagem_status.xlsx atualizado com sucesso para o arquivo Piloto - MRP_01.08 - MPS e Ciclo P07.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Pasta onde os novos arquivos serão verificados\n",
    "pasta_dados = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/4 - MRP/1 - MPS Daily/'\n",
    "\n",
    "def verificar_novo_arquivo():\n",
    "    arquivos = os.listdir(pasta_dados)\n",
    "    arquivos = [arquivo for arquivo in arquivos if arquivo.startswith('Piloto - MRP_') and arquivo.endswith('.xlsx')]\n",
    "    if arquivos:\n",
    "        arquivo_recente = max(arquivos, key=lambda x: os.path.getmtime(os.path.join(pasta_dados, x)))\n",
    "        return arquivo_recente\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def processar_arquivo(arquivo):\n",
    "    # Caminho completo do arquivo\n",
    "    caminho_arquivo = os.path.join(pasta_dados, arquivo)\n",
    "    # Ler a aba específica do arquivo Excel\n",
    "    aba_stock = '6. Stock'\n",
    "    try:\n",
    "        df_stock = pd.read_excel(caminho_arquivo, sheet_name=aba_stock)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Verificar se as colunas \"Sub-tipo\" e \"Cash\" estão presentes\n",
    "    if 'Sub-tipo' not in df_stock.columns or 'Cash' not in df_stock.columns:\n",
    "        print(f\"O arquivo {arquivo} não contém as colunas necessárias na aba '6. Stock'. Ignorando.\")\n",
    "        return\n",
    "\n",
    "    df_stock.columns = df_stock.columns.str.strip()\n",
    "    df_stock_resumo = df_stock.groupby('Sub-tipo')['Cash'].sum().reset_index()\n",
    "    df_stock_resumo['data'] = datetime.today().date().strftime('%d/%m/%Y')\n",
    "\n",
    "    # Nome do novo arquivo Excel\n",
    "    diretorio_destino = Path('C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python')\n",
    "    arquivo_destino = diretorio_destino / 'contagem_status.xlsx'\n",
    "\n",
    "    # Verificar se o diretório de destino existe, criar se não existir\n",
    "    diretorio_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if arquivo_destino.exists():\n",
    "        try:\n",
    "            with pd.ExcelWriter(arquivo_destino, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "                df_stock_resumo.to_excel(writer, sheet_name='Cash', index=False, header=False, startrow=writer.sheets['Cash'].max_row)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo {arquivo_destino}: {e}\")\n",
    "    else:\n",
    "        with pd.ExcelWriter(arquivo_destino, engine='openpyxl', mode='w') as writer:\n",
    "            df_stock_resumo.to_excel(writer, sheet_name='Cash', index=False)\n",
    "\n",
    "    print(f\"Arquivo {arquivo_destino} atualizado com sucesso para o arquivo {arquivo}.\")\n",
    "\n",
    "def main():\n",
    "    novo_arquivo = verificar_novo_arquivo()\n",
    "    if not novo_arquivo:\n",
    "        print(\"Não há novos arquivos para processar. Encerrando o programa.\")\n",
    "        return\n",
    "\n",
    "    processar_arquivo(novo_arquivo)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Past Due PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx atualizado com sucesso para o arquivo Piloto - MRP_01.08 - MPS e Ciclo P07.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Pasta onde os novos arquivos serão verificados\n",
    "pasta_dados = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/4 - MRP/1 - MPS Daily/'\n",
    "\n",
    "# Arquivo de registro para controlar a data da última execução para cada arquivo\n",
    "arquivo_log = 'last_run_log.txt'\n",
    "\n",
    "def verificar_novo_arquivo():\n",
    "    arquivos = os.listdir(pasta_dados)\n",
    "    arquivos = [arquivo for arquivo in arquivos if arquivo.startswith('Piloto - MRP_') and arquivo.endswith('.xlsx')]\n",
    "    if arquivos:\n",
    "        arquivo_recente = max(arquivos, key=lambda x: os.path.getmtime(os.path.join(pasta_dados, x)))\n",
    "        return arquivo_recente\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def carregar_log():\n",
    "    if os.path.exists(arquivo_log):\n",
    "        with open(arquivo_log, 'r') as f:\n",
    "            log = f.read().strip().split('\\n')\n",
    "        log_dict = {linha.split(',')[0]: linha.split(',')[1] for linha in log}\n",
    "        return log_dict\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def salvar_log(log_dict):\n",
    "    with open(arquivo_log, 'w') as f:\n",
    "        for arquivo, data in log_dict.items():\n",
    "            f.write(f\"{arquivo},{data}\\n\")\n",
    "\n",
    "def verificar_ultima_execucao(arquivo, log_dict):\n",
    "    return log_dict.get(arquivo, None)\n",
    "\n",
    "def registrar_ultima_execucao(arquivo, data, log_dict):\n",
    "    log_dict[arquivo] = data\n",
    "\n",
    "def obter_data_util_anterior(data):\n",
    "    if data.weekday() == 0:  # Segunda-feira\n",
    "        return data - timedelta(days=3)  # Sexta-feira anterior\n",
    "    elif data.weekday() == 6:  # Domingo\n",
    "        return data - timedelta(days=2)  # Sexta-feira anterior\n",
    "    else:\n",
    "        return data - timedelta(days=1)  # Dia útil anterior\n",
    "\n",
    "def processar_arquivo(arquivo, log_dict):\n",
    "    # Caminho completo do arquivo\n",
    "    caminho_arquivo = os.path.join(pasta_dados, arquivo)\n",
    "    # Ler a aba específica do arquivo Excel\n",
    "    aba = '7. Pedidos'\n",
    "    try:\n",
    "        df = pd.read_excel(caminho_arquivo, sheet_name=aba)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Verificar se as colunas necessárias estão presentes\n",
    "    colunas_necessarias = ['Data documento', 'Material', 'Pedido', 'Past Due PO']\n",
    "    for coluna in colunas_necessarias:\n",
    "        if coluna not in df.columns:\n",
    "            print(f\"O arquivo {arquivo} não contém a coluna '{coluna}'. Ignorando.\")\n",
    "            return\n",
    "\n",
    "    # Filtrar dados pela data útil anterior\n",
    "    data_hoje = datetime.today().date()\n",
    "    data_util_anterior = obter_data_util_anterior(data_hoje)\n",
    "    df['Data documento'] = pd.to_datetime(df['Data documento']).dt.date\n",
    "    df_filtrado = df[df['Data documento'] == data_util_anterior]\n",
    "\n",
    "    # Selecionar colunas desejadas\n",
    "    df_final = df_filtrado[['Data documento', 'Material', 'Pedido', 'Past Due PO']]\n",
    "\n",
    "    # Nome do novo arquivo Excel\n",
    "    arquivo_destino = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx'\n",
    "\n",
    "    # Carregar o arquivo existente ou criar um novo DataFrame se o arquivo não existir\n",
    "    if os.path.exists(arquivo_destino):\n",
    "        # Carregar a planilha existente sem sobrescrever outras abas\n",
    "        with pd.ExcelFile(arquivo_destino) as reader:\n",
    "            # Carregar todas as abas existentes em um dicionário\n",
    "            planilhas = {sheet: pd.read_excel(reader, sheet_name=sheet) for sheet in reader.sheet_names}\n",
    "        # Atualizar ou criar a aba 'Pedidos de ontem'\n",
    "        if 'Pedidos de ontem' in planilhas:\n",
    "            df_existente = planilhas['Pedidos de ontem']\n",
    "            # Concatenar apenas se os DataFrames não estiverem vazios\n",
    "            if not df_existente.empty and not df_final.empty:\n",
    "                df_final = pd.concat([df_existente, df_final], ignore_index=True)\n",
    "            elif df_existente.empty:\n",
    "                df_final = df_existente\n",
    "        planilhas['Pedidos de ontem'] = df_final\n",
    "    else:\n",
    "        planilhas = {'Pedidos de ontem': df_final}\n",
    "\n",
    "    # Salvar todas as abas de volta na planilha\n",
    "    try:\n",
    "        with pd.ExcelWriter(arquivo_destino, engine='openpyxl') as writer:\n",
    "            for sheet_name, df_sheet in planilhas.items():\n",
    "                df_sheet.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    except PermissionError:\n",
    "        print(f\"Erro de permissão ao tentar acessar o arquivo {arquivo_destino}. Verifique se ele não está aberto ou bloqueado.\")\n",
    "\n",
    "    data_atual = data_hoje.strftime('%d/%m/%Y')\n",
    "    print(f\"Arquivo {arquivo_destino} atualizado com sucesso para o arquivo {arquivo}.\")\n",
    "    registrar_ultima_execucao(arquivo, data_atual, log_dict)\n",
    "\n",
    "def main():\n",
    "    log_dict = carregar_log()\n",
    "    novo_arquivo = verificar_novo_arquivo()\n",
    "    if not novo_arquivo:\n",
    "        print(\"Não há novos arquivos para processar. Encerrando o programa.\")\n",
    "        return\n",
    "\n",
    "    processar_arquivo(novo_arquivo, log_dict)\n",
    "\n",
    "    salvar_log(log_dict)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recebimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo TXT lido com sucesso.\n",
      "Dados processados e DataFrame filtrado criado com 16 linhas.\n",
      "Arquivo Excel carregado com sucesso.\n",
      "Aba 'recebimento' encontrada. Dados serão adicionados a partir da linha 365.\n",
      "Dados adicionados e arquivo Excel salvo: C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook, Workbook\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Caminho para o arquivo TXT\n",
    "txt_file_path = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/SAP/Job MB51_RECEBIMENTOS, Step 1.txt'\n",
    "\n",
    "# Ler o conteúdo do arquivo\n",
    "try:\n",
    "    with open(txt_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    print(\"Arquivo TXT lido com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo TXT: {e}\")\n",
    "    raise\n",
    "\n",
    "# Encontrar a linha que começa com \"Pedido\"\n",
    "start_index = None\n",
    "for i, line in enumerate(lines):\n",
    "    if \"Pedido\" in line:\n",
    "        start_index = i + 1\n",
    "        break\n",
    "\n",
    "if start_index is None:\n",
    "    print(\"A linha 'Pedido' não foi encontrada no arquivo.\")\n",
    "    raise ValueError(\"Linha 'Pedido' não encontrada\")\n",
    "\n",
    "# Extrair as linhas de dados a partir da linha \"Pedido\"\n",
    "data_lines = lines[start_index:]\n",
    "\n",
    "# Processar os dados para remover duplicatas e separar por colunas\n",
    "data = []\n",
    "for line in data_lines:\n",
    "    # Verificar se a linha contém números e não é uma linha de separação\n",
    "    if any(re.search(r'\\d', part) for part in line.split('|')) and not re.fullmatch(r'[-\\s|]+', line):\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) > 1:\n",
    "            data.append(tuple(part.strip() for part in parts if part.strip()))\n",
    "\n",
    "if not data:\n",
    "    print(\"Nenhum dado válido encontrado após a linha 'Pedido'.\")\n",
    "    raise ValueError(\"Nenhum dado válido encontrado\")\n",
    "\n",
    "# Criar um DataFrame\n",
    "columns = ['Pedido', 'Item', 'Data lcto', 'Material', 'Qtd']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Substituir vírgulas por pontos e remover pontos de separação de milhar\n",
    "df['Qtd'] = df['Qtd'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "# Tratar quantidades negativas e valores nulos\n",
    "df['Qtd'] = df['Qtd'].apply(lambda x: -float(x[:-1]) if pd.notnull(x) and x.endswith('-') else float(x) if pd.notnull(x) else 0.0)\n",
    "\n",
    "# Remover duplicatas mantendo a primeira ocorrência\n",
    "df = df.drop_duplicates(subset=['Pedido', 'Item'])\n",
    "\n",
    "# Somar as quantidades por pedido\n",
    "summed_df = df.groupby('Pedido', as_index=False).agg({'Qtd': 'sum'})\n",
    "\n",
    "# Filtrar pedidos com quantidade total diferente de zero\n",
    "valid_pedidos = summed_df[summed_df['Qtd'] != 0]['Pedido']\n",
    "filtered_df = df[df['Pedido'].isin(valid_pedidos)].drop(columns=['Qtd'])\n",
    "\n",
    "# Adicionar coluna com a data atual\n",
    "filtered_df['Data Processamento'] = datetime.today().strftime('%d/%m/%Y')\n",
    "\n",
    "print(f\"Dados processados e DataFrame filtrado criado com {len(filtered_df)} linhas.\")\n",
    "\n",
    "# Caminho para a planilha Excel de saída\n",
    "excel_file_path = 'C:/Users/corteda1/Mars Inc/Brazil_MW_PlanningComex - Documents/__INPUT_DATA_FOR_AUTOMATION__/MRP/Python/contagem_status.xlsx'\n",
    "\n",
    "# Verificar se o arquivo Excel existe e é válido\n",
    "if os.path.exists(excel_file_path) and excel_file_path.endswith('.xlsx'):\n",
    "    try:\n",
    "        # Carregar a planilha existente\n",
    "        book = load_workbook(excel_file_path)\n",
    "        print(\"Arquivo Excel carregado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o arquivo Excel: {e}\")\n",
    "        book = Workbook()\n",
    "        sheet = book.active\n",
    "        sheet.title = \"recebimento\"\n",
    "        start_row = 1\n",
    "else:\n",
    "    book = Workbook()\n",
    "    sheet = book.active\n",
    "    sheet.title = \"recebimento\"\n",
    "    start_row = 1\n",
    "\n",
    "# Verificar se a aba 'recebimento' existe e determinar a linha inicial\n",
    "if 'recebimento' in book.sheetnames:\n",
    "    sheet = book['recebimento']\n",
    "    start_row = sheet.max_row + 1\n",
    "    print(f\"Aba 'recebimento' encontrada. Dados serão adicionados a partir da linha {start_row}.\")\n",
    "else:\n",
    "    sheet = book.create_sheet('recebimento')\n",
    "    start_row = 1\n",
    "    print(\"Aba 'recebimento' criada.\")\n",
    "\n",
    "# Adicionar os dados ao final da aba \"recebimento\"\n",
    "for row in filtered_df.itertuples(index=False, name=None):\n",
    "    sheet.append(row)\n",
    "\n",
    "# Salvar a planilha\n",
    "try:\n",
    "    book.save(excel_file_path)\n",
    "    # Garantir que a planilha seja editável\n",
    "    os.chmod(excel_file_path, 0o666)  # Permissões de leitura e escrita para todos\n",
    "    print(f\"Dados adicionados e arquivo Excel salvo: {excel_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao salvar o arquivo Excel: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
